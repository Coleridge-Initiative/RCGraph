{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rich Context: Knowledge Graph Visualization\n",
    "\n",
    "This notebook loads the Rich Context knowledge graph from the `tmp.jsonld` JSON-LD file prepared by the `RCGraph` workflow.\n",
    "It runs graph analytics on the KG using the `NetworkX` library, then creates an interactive visualization using the `PyVis` library.\n",
    "\n",
    "The following installations are needed, if these libraries haven't already been installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pyvis\n",
    "!pip install networkx\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the KG from the `tmp.jsonld` file…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "IDS = []\n",
    "LABELS = {}\n",
    "\n",
    "publications = {}\n",
    "providers = {}\n",
    "datasets = {}\n",
    "journals = {}\n",
    "authors = {}\n",
    "\n",
    "\n",
    "def get_id (id):\n",
    "    \"\"\" lookup the numeric ID for an element\n",
    "    \"\"\"\n",
    "    global IDS\n",
    "    return int(IDS.index(id))\n",
    "\n",
    "\n",
    "def parse_metadata (elem):\n",
    "    \"\"\" parse the required metadata items from one element in the graph\n",
    "    \"\"\"\n",
    "    global IDS, LABELS\n",
    "    \n",
    "    kind = elem[\"@type\"]\n",
    "    \n",
    "    #print(elem[\"dct:title\"])\n",
    "    title = elem[\"dct:title\"][\"@value\"]\n",
    "\n",
    "    id = elem[\"@id\"].split(\"#\")[1]\n",
    "    IDS.append(id)\n",
    "    LABELS[get_id(id)] = title\n",
    "\n",
    "    return id, kind, title\n",
    "\n",
    "\n",
    "# input the corpus from the JSON-LD file\n",
    "\n",
    "filename = \"tmp.jsonld\"\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    jld_corpus = json.load(f)\n",
    "    corpus = jld_corpus[\"@graph\"]\n",
    "    \n",
    "# report summary stats\n",
    "\n",
    "print(f\"{len(corpus)} corpus elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the providers\n",
    "\n",
    "for elem in corpus:\n",
    "    id, kind, title = parse_metadata(elem)\n",
    "\n",
    "    if kind == \"Provider\":\n",
    "        if \"dct:identifier\" in elem:\n",
    "            ror = elem[\"dct:identifier\"][\"@value\"]\n",
    "        else:\n",
    "            ror = \"\"\n",
    "\n",
    "        view = {\n",
    "            \"id\": id,\n",
    "            \"title\": title,\n",
    "            \"ror\": ror\n",
    "        }\n",
    "\n",
    "        providers[id] = view\n",
    "\n",
    "# load the datasets\n",
    "\n",
    "for elem in corpus:\n",
    "    id, kind, title = parse_metadata(elem)\n",
    "\n",
    "    if kind == \"Dataset\":\n",
    "        prov_id = elem[\"dct:publisher\"][\"@value\"]\n",
    "\n",
    "        view = {\n",
    "            \"id\": id,\n",
    "            \"title\": title,\n",
    "            \"provider\": prov_id\n",
    "        }\n",
    "\n",
    "        datasets[id] = view\n",
    "\n",
    "# load the journals\n",
    "\n",
    "for elem in corpus:\n",
    "    id, kind, title = parse_metadata(elem)\n",
    "\n",
    "    if kind == \"Journal\":\n",
    "        if \"dct:identifier\" in elem:\n",
    "            issn = elem[\"dct:identifier\"][\"@value\"]\n",
    "        else:\n",
    "            issn = \"\"\n",
    "\n",
    "        view = {\n",
    "            \"id\": id,\n",
    "            \"title\": title,\n",
    "            \"issn\": issn\n",
    "        }\n",
    "\n",
    "        journals[id] = view\n",
    "\n",
    "# load the authors\n",
    "\n",
    "for elem in corpus:\n",
    "    id, kind, title = parse_metadata(elem)\n",
    "\n",
    "    if kind == \"Author\":\n",
    "        if \"dct:identifier\" in elem:\n",
    "            orcid = elem[\"dct:identifier\"][\"@value\"]\n",
    "        else:\n",
    "            orcid = \"\"\n",
    "\n",
    "        view = {\n",
    "            \"id\": id,\n",
    "            \"title\": title,\n",
    "            \"orcid\": orcid\n",
    "        }\n",
    "\n",
    "        authors[id] = view\n",
    "\n",
    "# load the publications\n",
    "\n",
    "for elem in corpus:\n",
    "    id, kind, title = parse_metadata(elem)\n",
    "\n",
    "    if kind == \"ResearchPublication\":\n",
    "        # link the datasets\n",
    "        data_list = []\n",
    "        l = elem[\"cito:citesAsDataSource\"]\n",
    "\n",
    "        if isinstance(l, dict):\n",
    "            l = [l]\n",
    "            \n",
    "        for d in l:\n",
    "            data_id = d[\"@id\"].split(\"#\")[1]\n",
    "            datasets[data_id][\"used\"] = True\n",
    "            data_list.append(data_id)\n",
    "\n",
    "            prov_id = datasets[data_id][\"provider\"]\n",
    "            providers[prov_id][\"used\"] = True\n",
    "\n",
    "        # link the authors\n",
    "        auth_list = []\n",
    "        \n",
    "        if \"dct:creator\" in elem:\n",
    "            l = elem[\"dct:creator\"]\n",
    "        else:\n",
    "            l = []\n",
    "\n",
    "        if isinstance(l, dict):\n",
    "            l = [l]\n",
    "\n",
    "        for a in l:\n",
    "            auth_id = a[\"@id\"].split(\"#\")[1]\n",
    "            authors[auth_id][\"used\"] = True\n",
    "            auth_list.append(auth_id)\n",
    "\n",
    "        # add DOI\n",
    "        if \"dct:identifier\" in elem:\n",
    "            doi = elem[\"dct:identifier\"][\"@value\"]\n",
    "        else:\n",
    "            doi = \"\"\n",
    "\n",
    "        if \"dct:publisher\" in elem:\n",
    "            jour_id = elem[\"dct:publisher\"][\"@id\"].split(\"#\")[1]\n",
    "            journals[jour_id][\"used\"] = True\n",
    "        else:\n",
    "            journal = None\n",
    "\n",
    "        view = {\n",
    "            \"id\": id,\n",
    "            \"title\": title,\n",
    "            \"doi\": doi,\n",
    "            \"journal\": jour_id,\n",
    "            \"datasets\": data_list,\n",
    "            \"authors\": auth_list\n",
    "        }\n",
    "\n",
    "        publications[id] = view\n",
    "\n",
    "# report summary stats\n",
    "\n",
    "print(f\"{len(publications)} publications\")\n",
    "print(f\"{len(journals)} journals\")\n",
    "print(f\"{len(providers)} providers\")\n",
    "print(f\"{len(datasets)} datasets\")\n",
    "print(f\"{len(authors)} authors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate graph analytics…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nxg = nx.Graph()\n",
    "\n",
    "for p in providers.values():\n",
    "    if \"used\" in p:\n",
    "        nxg.add_node(get_id(p[\"id\"]))\n",
    "\n",
    "for d in datasets.values():\n",
    "    if \"used\" in d:\n",
    "        nxg.add_node(get_id(d[\"id\"]))\n",
    "        nxg.add_edge(get_id(d[\"id\"]), get_id(d[\"provider\"]))\n",
    "\n",
    "for a in authors.values():\n",
    "    if \"used\" in a:\n",
    "        nxg.add_node(get_id(a[\"id\"]))\n",
    "\n",
    "for j in journals.values():\n",
    "    if \"used\" in j:\n",
    "        nxg.add_node(get_id(j[\"id\"]))\n",
    "\n",
    "for p in publications.values():\n",
    "    nxg.add_node(get_id(p[\"id\"]))\n",
    "\n",
    "    if p[\"journal\"]:\n",
    "        nxg.add_edge(get_id(p[\"id\"]), get_id(p[\"journal\"]))\n",
    "\n",
    "    for d in p[\"datasets\"]:\n",
    "        nxg.add_edge(get_id(p[\"id\"]), get_id(d))\n",
    "\n",
    "    for a in p[\"authors\"]:\n",
    "        nxg.add_edge(get_id(p[\"id\"]), get_id(a))\n",
    "    \n",
    "#graph.add_edge(node0, node1, weight=self.edge_weight)\n",
    "#graph.edge_betweenness_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run quantile analysis on he centrality results, to assess the relative impact of each element in the KG…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calc_quantiles (metrics, num_q):\n",
    "    \"\"\" calculate `num` quantiles for the given list                                                                             \n",
    "    \"\"\"\n",
    "    bins = np.linspace(0, 1, num=num_q, endpoint=True)\n",
    "    s = pd.Series(metrics)\n",
    "    q = s.quantile(bins, interpolation=\"nearest\")\n",
    "\n",
    "    try:\n",
    "        dig = np.digitize(metrics, q) - 1\n",
    "    except ValueError as e:\n",
    "        print(\"ValueError:\", str(e), metrics, s, q, bins)\n",
    "        sys.exit(-1)\n",
    "\n",
    "    quantiles = []\n",
    "\n",
    "    for idx, q_hi in q.iteritems():\n",
    "        quantiles.append(q_hi)\n",
    "\n",
    "    return quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "result = nx.pagerank(nxg)\n",
    "#result = nx.edge_betweenness_centrality(nxg)\n",
    "ranks = list(result.values())\n",
    "\n",
    "quant = calc_quantiles(ranks, num_q=10)\n",
    "num_quant = len(quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxg_set = set([])\n",
    "\n",
    "for n in nxg.nodes:\n",
    "    nxg_set.add(int(n))\n",
    "\n",
    "for id, rank in sorted(result.items(), key=itemgetter(1), reverse=True):\n",
    "    if id not in nxg_set:\n",
    "        print(f\"{id} not in nxg_set\")\n",
    "    if id not in LABELS:\n",
    "        print(f\"{IDS[id]} not in LABELS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_SCALE = {}\n",
    "SCALE_FACTOR = 3\n",
    "\n",
    "for id, rank in sorted(result.items(), key=itemgetter(1), reverse=True):\n",
    "    impact = percentileofscore(ranks, rank)\n",
    "    scale = (((impact / num_quant) + 5) * SCALE_FACTOR)\n",
    "    IDS_SCALE[id] = [int(round(scale)), impact / 100.0]\n",
    "    print(\"{:^5}\\t{:.4f}\\t{:.4f}\\t{}\".format(id, rank, impact / 100.0, LABELS[id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `constrain()` function to constrain the graph to the neighborhood of a specified node. This is based on a breadth-first search, with a `limit` parameter to constrain the diameter of the neighborhood in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBGRAPH = nxg_set\n",
    "\n",
    "def constrain (limit, search_term):\n",
    "    global SUBGRAPH\n",
    "    \n",
    "    for node_id, label in LABELS.items():\n",
    "        if label == search_term:\n",
    "            r = nx.bfs_edges(nxg, source=node_id, depth_limit=limit)\n",
    "            SUBGRAPH = set([node_id])\n",
    "\n",
    "            for _, neighbor in r:\n",
    "                SUBGRAPH.add(neighbor)\n",
    "\n",
    "\n",
    "#constrain(limit=4, search_term=\"NOAA\")\n",
    "print(len(SUBGRAPH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, Markdown\n",
    "\n",
    "frags = []\n",
    "markdown_frag = \" - ![#{}](https://placehold.it/15/{}/000000?text=+) `{} {}`\"\n",
    "\n",
    "num_prov = len(SUBGRAPH.intersection(set([get_id(p) for p in providers.keys()])))\n",
    "frags.append(markdown_frag.format(\"ffa500\", \"ffa500\", num_prov, \"providers (orange)\"))\n",
    "\n",
    "num_data = len(SUBGRAPH.intersection(set([get_id(d) for d in datasets.keys()])))\n",
    "frags.append(markdown_frag.format(\"ff0000\", \"ff0000\", num_data, \"datasets (red)\"))\n",
    "\n",
    "num_auth = len(SUBGRAPH.intersection(set([get_id(a) for a in authors.keys()])))\n",
    "frags.append(markdown_frag.format(\"ff00ff\", \"ff00ff\", num_auth, \"authors (purple)\"))\n",
    "\n",
    "num_jour = len(SUBGRAPH.intersection(set([get_id(j) for j in journals.keys()])))\n",
    "frags.append(markdown_frag.format(\"008000\", \"008000\", num_jour, \"journals (green)\"))\n",
    "\n",
    "num_pubs = len(SUBGRAPH.intersection(set([get_id(p) for p in publications.keys()])))\n",
    "frags.append(markdown_frag.format(\"0000ff\", \"0000ff\", num_pubs, \"publications (blue)\"))\n",
    "\n",
    "LEGEND_MARKDOWN = \"\\n\".join(frags)\n",
    "print(LEGEND_MARKDOWN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an interactive visualization…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "g = Network(notebook=True, height=\"1000px\", width=\"100%\")\n",
    "g.force_atlas_2based()\n",
    "\n",
    "for p in providers.values():\n",
    "    if \"used\" in p:\n",
    "        p_id = get_id(p[\"id\"])\n",
    "        \n",
    "        if p_id in SUBGRAPH:\n",
    "            scale, impact = IDS_SCALE[p_id]\n",
    "            title = \"{}<br/>rank: {:.4f}<br/>{}\".format(p[\"title\"], impact, p[\"ror\"])\n",
    "            g.add_node(p_id, label=p[\"title\"], title=title, color=\"orange\", size=scale)\n",
    "\n",
    "for d in datasets.values():\n",
    "    if \"used\" in d:\n",
    "        d_id = get_id(d[\"id\"])\n",
    "        \n",
    "        if d_id in SUBGRAPH:\n",
    "            p_id = get_id(d[\"provider\"])\n",
    "            scale, impact = IDS_SCALE[d_id]\n",
    "            title = \"{}<br/>rank: {:.4f}<br/>provider: {}\".format(d[\"title\"], impact, LABELS[p_id])\n",
    "            g.add_node(d_id, label=d[\"title\"], title=title, color=\"red\", size=scale)\n",
    "\n",
    "            if p_id in SUBGRAPH:\n",
    "                g.add_edge(d_id, p_id, color=\"gray\")\n",
    "\n",
    "for a in authors.values():\n",
    "    if \"used\" in a:\n",
    "        a_id = get_id(a[\"id\"])\n",
    "\n",
    "        if a_id in SUBGRAPH:\n",
    "            scale, impact = IDS_SCALE[a_id]\n",
    "            title = \"{}<br/>rank: {:.4f}<br/>{}\".format(a[\"title\"], impact, a[\"orcid\"])\n",
    "            g.add_node(a_id, label=a[\"title\"], title=title, color=\"purple\", size=scale)\n",
    "\n",
    "for j in journals.values():\n",
    "    if \"used\" in j:\n",
    "        j_id = get_id(j[\"id\"])\n",
    "\n",
    "        if j_id in SUBGRAPH:\n",
    "            scale, impact = IDS_SCALE[j_id]\n",
    "            title = \"{}<br/>rank: {:.4f}<br/>{}\".format(j[\"title\"], impact, j[\"issn\"])\n",
    "            g.add_node(j_id, label=j[\"title\"], title=title, color=\"green\", size=scale)\n",
    "\n",
    "for p in publications.values():\n",
    "    p_id = get_id(p[\"id\"])\n",
    "\n",
    "    if p_id in SUBGRAPH:\n",
    "        scale, impact = IDS_SCALE[p_id]\n",
    "        title = \"{}<br/>rank: {:.4f}<br/>{}\".format(p[\"title\"], impact, p[\"doi\"])\n",
    "        g.add_node(p_id, label=p[\"title\"], title=title, color=\"blue\", size=scale)\n",
    "\n",
    "        if p[\"journal\"]:\n",
    "            j_id = get_id(p[\"journal\"])\n",
    "\n",
    "            if j_id in SUBGRAPH:\n",
    "                g.add_edge(p_id, j_id, color=\"gray\")\n",
    "\n",
    "        for d in p[\"datasets\"]:\n",
    "            d_id = get_id(d)\n",
    "            \n",
    "            if d_id in SUBGRAPH:\n",
    "                g.add_edge(p_id, d_id, color=\"gray\")\n",
    "\n",
    "        for a in p[\"authors\"]:\n",
    "            a_id = get_id(a)\n",
    "            \n",
    "            if a_id in SUBGRAPH:\n",
    "                g.add_edge(p_id, a_id, color=\"gray\")\n",
    "\n",
    "g.show_buttons()\n",
    "g.show(\"corpus.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LEGEND_MARKDOWN)\n",
    "display(Markdown(LEGEND_MARKDOWN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
